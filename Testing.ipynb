{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/birdalugureren/Testing-in-Python/blob/master/Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNprFcq27MBj"
   },
   "source": [
    "## Introduction\n",
    "There are 2 types of tests:\n",
    "1. An integration test checks that components in your application operate with each other.\n",
    "2. A unit test checks a small component in your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OT-teGj93Esp"
   },
   "source": [
    "This will not output anything on the REPL because the values are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "482qreAy2v38"
   },
   "outputs": [],
   "source": [
    "assert sum([1,2,3]) == 6, \"Should be 6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18msoLGn3Hvj"
   },
   "source": [
    "If the result from sum() is incorrect, this will fail with an AssertionError and the message \"Should be 6\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "-RaTG1BL25JD",
    "outputId": "f5013105-445c-44ce-e654-a14e0a7d5c49"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa10351dd942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Should be 6\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Should be 6"
     ]
    }
   ],
   "source": [
    "assert sum([1, 1, 1]) == 6, \"Should be 6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJdXS67R3Sz8"
   },
   "source": [
    "Instead of testing on the REPL, you’ll want to put this into a new Python file called test_sum.py and execute it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3xnRROOQ3spl",
    "outputId": "2b73699a-6fcb-4efe-ebb8-367688869ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything passed\r\n"
     ]
    }
   ],
   "source": [
    "! python test_sum.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uStjFv2I4wH9"
   },
   "source": [
    "You tested with a list. Now test with a tuple as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "z4jIIFue3s4v",
    "outputId": "12900929-5970-47d8-8af8-deebc22c8eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"test_sum_2.py\", line 9, in <module>\n",
      "    test_sum_tuple()\n",
      "  File \"test_sum_2.py\", line 5, in test_sum_tuple\n",
      "    assert sum((1, 2, 2)) == 6, \"Should be 6\"\n",
      "AssertionError: Should be 6\n"
     ]
    }
   ],
   "source": [
    "! python test_sum_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-yetUKl5Fcl"
   },
   "source": [
    "Writing tests in this way is okay for a simple check, but what if more than one fails? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGsypDvq6cwt"
   },
   "source": [
    "## Test Runner\n",
    "The test runner is a special application designed for running tests, checking the output, and giving you tools for debugging and diagnosing tests and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BM7j43L-8Hl0"
   },
   "source": [
    "### Unittest\n",
    "unittest contains both a testing framework and a test runner. unittest requires that:\n",
    "- You put your tests into classes as methods\n",
    "- You use a series of special assertion methods in the unittest.TestCase class instead of the built-in assert statement\n",
    "\n",
    "Let's create a test_sum_unittest.py file by following the steps below:\n",
    "1. Import unittest from the standard library\n",
    "2. Create a class called TestSum that inherits from the TestCase class\n",
    "3. Convert the test functions into methods by adding self as the first argument\n",
    "4. Change the assertions to use the self.assertEqual() method on the TestCase class\n",
    "5. Change the command-line entry point to call unittest.main()\n",
    "\n",
    "one success (indicated with .) and one failure (indicated with F):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "gjP1eLM36X2b",
    "outputId": "b581e417-26c5-49f2-c85a-ea774020c538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".F\n",
      "======================================================================\n",
      "FAIL: test_sum_tuple (__main__.TestSum)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"test_sum_unittest.py\", line 8, in test_sum_tuple\n",
      "    self.assertEqual(sum((1,2,2)), 6, 'Should be 6')\n",
      "AssertionError: 5 != 6 : Should be 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "! python test_sum_unittest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vN00favYA8_p"
   },
   "source": [
    "### Nose2\n",
    "You may find that over time, as you write hundreds or even thousands of tests for your application, it becomes increasingly hard to understand and use the output from unittest. nose2 is compatible with any tests written using the unittest framework and can be used as a drop-in replacement for the unittest test runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "sSwBQqDg5F7p",
    "outputId": "bfe02873-1fff-4297-f20f-115a207a2a3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nose2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/ad/27561695e863f5df064f1715864afb3ebe723a6e19e875eca85570e0a7cd/nose2-0.9.2-py2.py3-none-any.whl (137kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 2.7MB/s \n",
      "\u001b[?25hCollecting coverage>=4.4.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/3e/fc18ecef69f174c13493576f46966053c1da07fd8721962530dc1a10b1ca/coverage-5.1-cp36-cp36m-manylinux1_x86_64.whl (227kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 7.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from nose2) (1.12.0)\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement coverage==3.7.1, but you'll have coverage 5.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: coveralls 0.5 has requirement coverage<3.999,>=3.6, but you'll have coverage 5.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: coverage, nose2\n",
      "  Found existing installation: coverage 3.7.1\n",
      "    Uninstalling coverage-3.7.1:\n",
      "      Successfully uninstalled coverage-3.7.1\n",
      "Successfully installed coverage-5.1 nose2-0.9.2\n",
      ".F..F\n",
      "======================================================================\n",
      "FAIL: test_sum_tuple (test_sum_unittest.TestSum)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/test_sum_unittest.py\", line 8, in test_sum_tuple\n",
      "    self.assertEqual(sum((1,2,2)), 6, 'Should be 6')\n",
      "AssertionError: 5 != 6 : Should be 6\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_sum_2.transplant_class.<locals>.C (test_sum_tuple)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/test_sum_2.py\", line 5, in test_sum_tuple\n",
      "    assert sum((1, 2, 2)) == 6, \"Should be 6\"\n",
      "AssertionError: Should be 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.003s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    }
   ],
   "source": [
    "! pip install nose2\n",
    "! python -m nose2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pg-qRHzmBuzS"
   },
   "source": [
    "### pytest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJ2Hd81WCe0j"
   },
   "source": [
    "pytest supports execution of unittest test cases. The real advantage of pytest comes by writing pytest test cases. pytest test cases are a series of functions in a Python file starting with the name test_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "5hfUNzn-45Ga",
    "outputId": "4c7775b0-e05c-4a56-aacd-398bcfd147c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1\n",
      "rootdir: /content, inifile:\n",
      "\n",
      "\u001b[1m\u001b[33m========================= no tests ran in 0.00 seconds =========================\u001b[0m\n",
      "\u001b[31mERROR: file not found: test_sample.py\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest test_sample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your application is a single script, you can import any attributes of the script, such as classes, functions, and variables, using the built-in __import __ () function.\n",
    "```python\n",
    "target = __import__(\"my_sum.py\")\n",
    "sum = target.sum\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Structure a Simple Test\n",
    "\n",
    "You’ll want to first make a couple of decisions:\n",
    "1. What do you want to test?\n",
    "2. Are you writing a unit test or an integration test?\n",
    "\n",
    "Workflow:\n",
    "1. Create your inputs\n",
    "2. Execute the code being tested, capturing the output\n",
    "3. Compare the output with an expected result\n",
    "\n",
    "For this application, you’re testing mysum:\n",
    "1. Can it sum a list of whole numbers (integers)?\n",
    "2. Can it sum a tuple or set?\n",
    "3. Can it sum a list of floats?\n",
    "4. What happens when you provide it with a bad value, such as a single integer or a string?\n",
    "5. What happens when one of the values is negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run test_my_sum.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6hzYtI73tGK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hx2Sc1eM3tJA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgTw6ph23tK3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNg0rgRoGmennDN0JfHAzY8",
   "collapsed_sections": [
    "dNprFcq27MBj",
    "BM7j43L-8Hl0",
    "vN00favYA8_p"
   ],
   "include_colab_link": true,
   "name": "Testing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
